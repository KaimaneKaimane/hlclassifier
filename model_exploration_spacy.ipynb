{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "import pickle\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Load spacy stopwords\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "# Load uci\n",
    "dataset_path = Path.cwd() / Path('dataset/cleaned/uci-news-aggregator.csv')\n",
    "datasets['uci'] = pd.read_csv(dataset_path)\n",
    "\n",
    "# Load news_v2\n",
    "dataset_path = Path.cwd() / Path('dataset/cleaned/News_Category_Dataset_v2.csv')\n",
    "datasets['news_v2'] = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, val, test split\n",
    "Split the dataset as specified in the task (80/15/5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(features, labels):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        np.array(features), \n",
    "        np.array(labels), \n",
    "        test_size=0.05, # 5 % test\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        np.array(x_train), \n",
    "        np.array(y_train), \n",
    "        test_size=3/19, # this evens out to 80% train 15% validation\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print('  train:', len(x_train))\n",
    "    print('  val:', len(x_val))\n",
    "    print('  test:', len(x_test))\n",
    "    \n",
    "    return x_train, x_test, x_val, y_val, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    \n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer using spaCy\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, x, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [clean_text(text) for text in x]\n",
    "\n",
    "    def fit(self, x, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested both simple vectorizers for spacy\n",
    "tfidf performed much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(vectorizer, classifier, x_train,y_train):\n",
    "    # Create spacy pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('cleaner', predictors()),\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # model generation\n",
    "    pipe.fit(x_train,y_train)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select classifier & vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing simple bow vectorizer\n",
    "bow_vector = CountVectorizer(\n",
    "    tokenizer=spacy_tokenizer, \n",
    "    ngram_range=(1,1)\n",
    ")\n",
    "\n",
    "# testing tfidf vectorizer\n",
    "tfidf_vector = TfidfVectorizer(\n",
    "    tokenizer=spacy_tokenizer,\n",
    "    min_df=3,\n",
    "    ngram_range=(1,5),\n",
    ")\n",
    "\n",
    "#classifier = LogisticRegression()\n",
    "classifier = LinearSVC()\n",
    "# classifier = SVC() # takes too long to train (more than 8 hours for news_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Val Test Split uci\n",
      "  train: 337935\n",
      "  val: 63363\n",
      "  test: 21121\n",
      "Train on uci\n",
      "Evaluate Model\n",
      "  Validation Accuracy: 0.9577671511765541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.94      0.94      0.94     17368\n",
      "           e       0.98      0.98      0.98     22845\n",
      "           m       0.97      0.94      0.95      6932\n",
      "           t       0.94      0.94      0.94     16218\n",
      "\n",
      "    accuracy                           0.96     63363\n",
      "   macro avg       0.96      0.95      0.96     63363\n",
      "weighted avg       0.96      0.96      0.96     63363\n",
      "\n",
      "  Test Accuracy: 0.9569149188011932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.94      0.94      0.94      5857\n",
      "           e       0.98      0.98      0.98      7647\n",
      "           m       0.96      0.95      0.95      2207\n",
      "           t       0.94      0.95      0.95      5410\n",
      "\n",
      "    accuracy                           0.96     21121\n",
      "   macro avg       0.96      0.95      0.95     21121\n",
      "weighted avg       0.96      0.96      0.96     21121\n",
      "\n",
      "\n",
      "Train Val Test Split news_v2\n",
      "  train: 160677\n",
      "  val: 30127\n",
      "  test: 10043\n",
      "Train on news_v2\n",
      "Evaluate Model\n",
      "  Validation Accuracy: 0.5922594350582534\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.28      0.20      0.24       244\n",
      "ARTS & CULTURE       0.34      0.19      0.24       221\n",
      "  BLACK VOICES       0.52      0.46      0.49       690\n",
      "      BUSINESS       0.50      0.47      0.48       901\n",
      "       COLLEGE       0.42      0.36      0.39       177\n",
      "        COMEDY       0.55      0.43      0.49       823\n",
      "         CRIME       0.55      0.56      0.55       520\n",
      "CULTURE & ARTS       0.43      0.29      0.35       161\n",
      "       DIVORCE       0.76      0.69      0.73       527\n",
      "     EDUCATION       0.44      0.30      0.36       166\n",
      " ENTERTAINMENT       0.64      0.74      0.69      2399\n",
      "   ENVIRONMENT       0.44      0.28      0.34       185\n",
      "         FIFTY       0.30      0.19      0.23       203\n",
      "  FOOD & DRINK       0.63      0.69      0.66       913\n",
      "     GOOD NEWS       0.33      0.22      0.27       210\n",
      "         GREEN       0.39      0.35      0.37       384\n",
      "HEALTHY LIVING       0.30      0.21      0.25       992\n",
      " HOME & LIVING       0.71      0.72      0.71       649\n",
      "        IMPACT       0.34      0.26      0.30       513\n",
      " LATINO VOICES       0.61      0.31      0.42       175\n",
      "         MEDIA       0.62      0.47      0.53       446\n",
      "         MONEY       0.43      0.35      0.39       252\n",
      "     PARENTING       0.50      0.56      0.53      1325\n",
      "       PARENTS       0.35      0.24      0.28       626\n",
      "      POLITICS       0.72      0.84      0.77      4867\n",
      "  QUEER VOICES       0.74      0.69      0.72       961\n",
      "      RELIGION       0.63      0.51      0.56       393\n",
      "       SCIENCE       0.58      0.48      0.53       317\n",
      "        SPORTS       0.69      0.73      0.71       735\n",
      "         STYLE       0.39      0.24      0.30       324\n",
      "STYLE & BEAUTY       0.73      0.81      0.77      1438\n",
      "         TASTE       0.33      0.22      0.26       306\n",
      "          TECH       0.51      0.47      0.49       324\n",
      " THE WORLDPOST       0.49      0.46      0.48       524\n",
      "        TRAVEL       0.70      0.76      0.73      1463\n",
      "      WEDDINGS       0.77      0.77      0.77       542\n",
      "    WEIRD NEWS       0.36      0.28      0.31       404\n",
      "      WELLNESS       0.52      0.67      0.58      2619\n",
      "         WOMEN       0.37      0.31      0.34       517\n",
      "    WORLD NEWS       0.42      0.27      0.33       314\n",
      "     WORLDPOST       0.38      0.31      0.34       377\n",
      "\n",
      "      accuracy                           0.59     30127\n",
      "     macro avg       0.50      0.45      0.47     30127\n",
      "  weighted avg       0.58      0.59      0.58     30127\n",
      "\n",
      "  Test Accuracy: 0.5861794284576322\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.40      0.22      0.29        89\n",
      "ARTS & CULTURE       0.16      0.13      0.14        55\n",
      "  BLACK VOICES       0.48      0.38      0.42       208\n",
      "      BUSINESS       0.44      0.46      0.45       247\n",
      "       COLLEGE       0.47      0.51      0.49        53\n",
      "        COMEDY       0.58      0.46      0.51       291\n",
      "         CRIME       0.51      0.53      0.52       162\n",
      "CULTURE & ARTS       0.47      0.31      0.37        45\n",
      "       DIVORCE       0.75      0.70      0.73       166\n",
      "     EDUCATION       0.31      0.25      0.28        44\n",
      " ENTERTAINMENT       0.62      0.73      0.67       775\n",
      "   ENVIRONMENT       0.33      0.23      0.27        60\n",
      "         FIFTY       0.42      0.22      0.29        77\n",
      "  FOOD & DRINK       0.57      0.66      0.61       307\n",
      "     GOOD NEWS       0.41      0.23      0.29        70\n",
      "         GREEN       0.43      0.39      0.41       145\n",
      "HEALTHY LIVING       0.25      0.17      0.21       327\n",
      " HOME & LIVING       0.71      0.74      0.72       205\n",
      "        IMPACT       0.40      0.28      0.33       205\n",
      " LATINO VOICES       0.54      0.35      0.43        54\n",
      "         MEDIA       0.55      0.44      0.49       136\n",
      "         MONEY       0.56      0.43      0.49        81\n",
      "     PARENTING       0.49      0.55      0.52       459\n",
      "       PARENTS       0.25      0.21      0.23       183\n",
      "      POLITICS       0.72      0.82      0.77      1663\n",
      "  QUEER VOICES       0.76      0.68      0.71       308\n",
      "      RELIGION       0.50      0.42      0.46       120\n",
      "       SCIENCE       0.59      0.41      0.49       128\n",
      "        SPORTS       0.69      0.72      0.70       236\n",
      "         STYLE       0.51      0.34      0.41       131\n",
      "STYLE & BEAUTY       0.73      0.78      0.76       480\n",
      "         TASTE       0.30      0.16      0.21       108\n",
      "          TECH       0.41      0.36      0.38        92\n",
      " THE WORLDPOST       0.52      0.47      0.49       191\n",
      "        TRAVEL       0.67      0.78      0.72       504\n",
      "      WEDDINGS       0.82      0.78      0.80       217\n",
      "    WEIRD NEWS       0.33      0.28      0.30       125\n",
      "      WELLNESS       0.54      0.70      0.61       908\n",
      "         WOMEN       0.39      0.30      0.34       172\n",
      "    WORLD NEWS       0.34      0.21      0.26       103\n",
      "     WORLDPOST       0.28      0.26      0.27       113\n",
      "\n",
      "      accuracy                           0.59     10043\n",
      "     macro avg       0.49      0.44      0.46     10043\n",
      "  weighted avg       0.57      0.59      0.57     10043\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in datasets.items():  \n",
    "    features = dataset['headline'] \n",
    "    labels = dataset['category']\n",
    "    \n",
    "    print('Train Val Test Split', dataset_name)   \n",
    "    x_train, x_test, x_val, y_val, y_train, y_test = train_val_test_split(features, labels)\n",
    "    \n",
    "    print('Train on', dataset_name)\n",
    "    model = train_model(tfidf_vector, classifier, x_train, y_train)\n",
    "    \n",
    "    print('Evaluate Model')\n",
    "    # Predicting with a val dataset\n",
    "    predicted = model.predict(x_val)\n",
    "    print('  Validation Accuracy:', metrics.accuracy_score(y_val, predicted))\n",
    "    \n",
    "    print(metrics.classification_report(y_val, predicted))\n",
    "    \n",
    "    # Predicting with a test dataset\n",
    "    predicted = model.predict(x_test)\n",
    "    print('  Test Accuracy:', metrics.accuracy_score(y_test, predicted))\n",
    "    \n",
    "    print(metrics.classification_report(y_test, predicted))\n",
    "    print('')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
